{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "c8941ad1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Screenshot saved as screenshot.png\n",
      "Cropped screenshot saved as cropped.png\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import subprocess\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from io import BytesIO\n",
    "import easyocr\n",
    "\n",
    "reader = easyocr.Reader(['en']) \n",
    "\n",
    "# ─── 1. ADB: connect to BlueStacks and grab a screenshot ──────────────────────\n",
    "device_id = '127.0.0.1:5555'  # change if BlueStacks uses another port\n",
    "subprocess.run(['adb', 'connect', device_id], check=True)\n",
    "screenshot = subprocess.check_output(['adb', '-s', device_id, 'exec-out', 'screencap', '-p'])\n",
    "\n",
    "# Save original screenshot\n",
    "with open('screenshot.png', 'wb') as f:\n",
    "    f.write(screenshot)\n",
    "print('Screenshot saved as screenshot.png')\n",
    "\n",
    "# ─── 2. Convert bytes to image and crop ────────────────────────────────────────\n",
    "image = Image.open(BytesIO(screenshot))\n",
    "\n",
    "# Define the crop box (left, upper, right, lower)\n",
    "crop_box = (420, 21, 464, 37)  # Adjust as needed\n",
    "cropped = image.crop(crop_box)\n",
    "\n",
    "# Save cropped image\n",
    "cropped.save('cropped.png')\n",
    "print('Cropped screenshot saved as cropped.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "30e0e1af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved as inverted_white.png\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Load image\n",
    "img = cv2.imread('cropped.png')  # BGR format\n",
    "# Create a mask where white pixels are (255, 255, 255)\n",
    "tolerance = 36\n",
    "\n",
    "# Define lower and upper bounds for \"near white\"\n",
    "lower_bound = np.array([255 - tolerance, 255 - tolerance, 255 - tolerance])\n",
    "upper_bound = np.array([255, 255, 255])\n",
    "\n",
    "# Create mask for near-white pixels\n",
    "white_mask = cv2.inRange(img, lower_bound, upper_bound)\n",
    "\n",
    "# Set white pixels to black, and others to white\n",
    "result = np.full_like(img, 255)  # Start with all white\n",
    "result[white_mask == 255] = [0, 0, 0]  # Set white pixels to black\n",
    "\n",
    "cv2.imwrite('inverted_white.png', result)\n",
    "print('Saved as inverted_white.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "e81108cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scale_factor = 10\n",
    "enlarged = cv2.resize(result, None, fx=scale_factor, fy=scale_factor, interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "cv2.imwrite('enlarged_result.png', enlarged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "7cb769e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected text: '6/6' with confidence 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Capta\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Run OCR on the enlarged image\n",
    "results = reader.readtext('cropped.png')  # or use 'cropped_enlarged_bw.png'\n",
    "\n",
    "# Step 3: Print results\n",
    "for bbox, text, confidence in results:\n",
    "    print(f\"Detected text: '{text}' with confidence {confidence:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b65b07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
